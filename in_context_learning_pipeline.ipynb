{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeoOrG6bylP5qESTiI53/v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yogesh914/cv-model-exploration/blob/main/in_context_learning_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In-Context Learning With Gemma-7b ðŸ¦‹"
      ],
      "metadata": {
        "id": "2gwfNAMGFMWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intial setup"
      ],
      "metadata": {
        "id": "5mbus2LSFkrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers pydub accelerate bitsandbytes hf_transfer"
      ],
      "metadata": {
        "id": "JS-urBdVFwaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "id": "mHotIJKUF3vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from IPython.display import Markdown, display\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from google.colab import userdata\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "from moviepy.editor import VideoFileClip\n",
        "import numpy as np\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "e-9fpkQ-FuOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZkNzplWFIuF"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transcription Using Whisper v3 (large)"
      ],
      "metadata": {
        "id": "qzv0wxzzGiXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "model_id = \"openai/whisper-large-v3\"\n",
        "\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, use_safetensors=True, torch_dtype=torch_dtype, low_cpu_mem_usage=True\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    max_new_tokens=500,\n",
        "    chunk_length_s=30,\n",
        "    batch_size=16,\n",
        "    return_timestamps=True,\n",
        "    device=device,\n",
        "    torch_dtype=torch_dtype\n",
        ")"
      ],
      "metadata": {
        "id": "WL2u0p4AFnoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video(video_file):\n",
        "    video = VideoFileClip(video_file)\n",
        "    audio = video.audio\n",
        "\n",
        "    audio_segment = AudioSegment.from_file(video_file, format=\"mp4\")\n",
        "    audio_segment = audio_segment.set_frame_rate(16000)\n",
        "    audio_array = np.array(audio_segment.get_array_of_samples())\n",
        "\n",
        "    if audio_segment.channels == 2:\n",
        "        audio_array = audio_array.reshape((-1, 2))\n",
        "        audio_array = audio_array.mean(axis=1)\n",
        "    audio_array = audio_array.astype(np.float32) / (2**15)\n",
        "\n",
        "    result = pipe(audio_array)\n",
        "    return result[\"text\"]"
      ],
      "metadata": {
        "id": "W_kQfsxRGplp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = '/content/drive/MyDrive/Colab Notebooks/data/beta_vids'\n",
        "\n",
        "captions = []\n",
        "video_files = sorted(os.listdir(data_folder))\n",
        "for video_file in video_files:\n",
        "    if not video_file.endswith('.mp4'):\n",
        "        continue\n",
        "    video_path = os.path.join(data_folder, video_file)\n",
        "    caption = process_video(video_path)\n",
        "    captions.append(caption)\n",
        "\n",
        "df_captions = pd.DataFrame({'Captions': captions})\n",
        "df_captions"
      ],
      "metadata": {
        "id": "EuD7A8kZGse5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Curating Dataset"
      ],
      "metadata": {
        "id": "obpy6SfFGvYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ema_survey = pd.read_csv(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/data/ema.csv\"))\n",
        "filtered_columns = ['ema_aware', 'ema_support', 'ema_insight', 'ema_fulfilled', 'ema_hopeless', 'ema_anxious', 'Trigger.Index']\n",
        "df_filtered = ema_survey[filtered_columns]\n",
        "\n",
        "df_final = df_filtered[ema_survey['User.Email'] == '']\n",
        "df_final = df_final.dropna()\n",
        "df_final.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "AX2feuHvHA6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge = pd.concat([df_captions, df_final], axis=1)\n",
        "merge.to_csv(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/data/merged_captions.csv\"), index=False)\n",
        "merge"
      ],
      "metadata": {
        "id": "TtsS7hwzG8xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Custom Prompt"
      ],
      "metadata": {
        "id": "CfyT8wCmHX3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = merge\n",
        "\n",
        "def format_prompt(row):\n",
        "    return f\"Caption: {row['Captions']}\\n\" \\\n",
        "           f\"Had you noticed you were feeling this way before we asked?: {int(row['ema_aware'])}\\n\" \\\n",
        "           f\"Did you feel you were supported by others?: {int(row['ema_support'])}\\n\" \\\n",
        "           f\"Did you recognize how your feelings were influencing your outlook on things?: {int(row['ema_insight'])}\\n\" \\\n",
        "           f\"How fulfilled did you feel?: {int(row['ema_fulfilled'])}\\n\" \\\n",
        "           f\"How hopeless did you feel?: {int(row['ema_hopeless'])}\\n\" \\\n",
        "           f\"How anxious did you feel?: {int(row['ema_anxious'])}\"\n",
        "\n",
        "prompt = \"\\n\\n\".join(df.iloc[3:6].apply(format_prompt, axis=1))\n",
        "\n",
        "instructions = \"\\n\\nBased on the previous entries, predict the ratings for the following caption on a scale of 1 to 5 and make sure to give only the your answer in json format and nothing else:\"\n",
        "last_caption = df.iloc[-1]['Captions']\n",
        "\n",
        "prompt += f\"{instructions}\\n\\nCaption: {last_caption}\\n\" \\\n",
        "          \"Had you noticed you were feeling this way before we asked?: \\n\" \\\n",
        "          \"Did you feel you were supported by others?: \\n\" \\\n",
        "          \"Did you recognize how your feelings were influencing your outlook on things?: \\n\" \\\n",
        "          \"How fulfilled did you feel?: \\n\" \\\n",
        "          \"How hopeless did you feel?: \\n\" \\\n",
        "          \"How anxious did you feel?: \"\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "0c1Lny14HXpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting Gemma-7b-it"
      ],
      "metadata": {
        "id": "CWz4F_tPILzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'\n",
        "torch.set_default_device(device)"
      ],
      "metadata": {
        "id": "-Ve6sdkAHyvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7b-it\", token=userdata.get('hgemma'))\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-7b-it\",\n",
        "                                             torch_dtype=\"auto\",\n",
        "                                             device_map=\"auto\", token=userdata.get('hgemma')\n",
        "                                             )"
      ],
      "metadata": {
        "id": "6lO_2angH4jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = [\n",
        "    { \"role\": \"user\", \"content\": prompt },\n",
        "]\n",
        "\n",
        "input = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
        "input"
      ],
      "metadata": {
        "id": "c7dKgz3QH6fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer.encode(prompt, add_special_tokens=True, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(input_ids=inputs.to(\"cuda\"),\n",
        "                         max_new_tokens=512)\n",
        "\n",
        "text = tokenizer.decode(outputs[0],skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "display(Markdown(text))"
      ],
      "metadata": {
        "id": "mFIJmPlBH-7_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}